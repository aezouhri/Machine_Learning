{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pickle\n",
    "from scipy.special import expit,softmax\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open MNIST data and create a subset with desired digits\n",
    "\n",
    "<font color=red>Change the code below to select a different subset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "y = np.asarray([int(numeric_string) for numeric_string in y])\n",
    "\n",
    "# Saving the temporary variables for fast retrieval\n",
    "with open('temp.pickle', 'wb') as handle:\n",
    "    pickle.dump([X, y], handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the temporary variables for fast retrieval\n",
    "with open('temp.pickle', 'rb') as handle:\n",
    "    X, y = pickle.load(handle)\n",
    "\n",
    "X = X\n",
    "    \n",
    "Nclasses = 3\n",
    "labelclasses = y<Nclasses\n",
    "Xnew = X[labelclasses]\n",
    "ynew = y[labelclasses]\n",
    "Nfeatures = np.size(Xnew,1)\n",
    "Nsamples = np.size(Xnew,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(Xnew, ynew, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.125, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "Nsamples = X_train.shape[0]\n",
    "Nfeatures = X_train.shape[1]\n",
    "\n",
    "X_train = X_train.T\n",
    "X_val = X_val.T\n",
    "X_test = X_test.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testLinearMCClassifier(a,X,y):\n",
    "    X = X.T\n",
    "    temp = np.zeros((X.shape[0],1))\n",
    "    X = np.append(X,temp,axis=1)\n",
    "    temp=[]\n",
    "    predict=np.zeros(Nclasses)\n",
    "    misclassifications =0\n",
    "    for i in range(X.shape[0]):\n",
    "        predict = X[i]@a.T\n",
    "        misclassifications =np.sum(np.argmax(predict) != y[i])\n",
    "  \n",
    "          \n",
    "    return misclassifications\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-classifications= 0 out of 61250 equivalent to 0.0 %\n",
      "Mis-classifications= 1 out of 8750 equivalent to 0.011428571428571429 %\n",
      "Mis-classifications= 0 out of 4354 equivalent to 0.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gaussianMultiChannelClassifier(Xtrain,ytrain):\n",
    "    Xtrain = Xtrain.T\n",
    "    matrix_one = np.zeros((Nclasses,Nfeatures+1))\n",
    "    \n",
    "    for i in range(Nclasses):\n",
    "        classi= Xtrain[ytrain==i]\n",
    "        mu = np.mean(classi,axis=0,keepdims = True)\n",
    "        temp = np.concatenate(((2*mu).T,(mu@mu.T)),axis =0)\n",
    "        matrix_one[i] = temp.T                      \n",
    "\n",
    "    return matrix_one\n",
    "        \n",
    "\n",
    "#------SIMPLE TESTING ON THE TRAINING DATA ITSELF --------------\n",
    "a = gaussianMultiChannelClassifier(X_train,y_train)\n",
    "#plt.imshow(np.reshape(a[0:784],(28,28)))\n",
    "\n",
    "train = testLinearMCClassifier(a,X_train,y_train)\n",
    "val = testLinearMCClassifier(a,X_val,y_val)\n",
    "test = testLinearMCClassifier(a,X_test,y_test)\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\")                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-classifications= 0 out of 61250 equivalent to 0.0 %\n",
      "Mis-classifications= 1 out of 8750 equivalent to 0.011428571428571429 %\n",
      "Mis-classifications= 1 out of 4354 equivalent to 0.022967386311437757 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def logisticRegressionMultiClassClassifier(Xtrain,ytrain,iterations=100,step_size=1e-4,verbose=False):\n",
    "\n",
    "    Xtrain = Xtrain.T    \n",
    "    test = np.zeros((Xtrain.shape[0],1))\n",
    "    Xtrain = np.append(Xtrain,test,axis=1)\n",
    "    a = 0.01*np.random.randn(Nfeatures+1)\n",
    "    t = np.squeeze(a.T@Xtrain.T)\n",
    "    s = softmax(t)\n",
    "    error = s-ytrain\n",
    "    for i in range(iterations):\n",
    "        replace_y = ytrain\n",
    "        temp=[1 if replace_y[x] ==1 else 0 for x in range(replace_y.shape[0])]\n",
    "        for j in range(Nclasses):\n",
    "            t = np.squeeze(np.matmul(np.transpose(a),Xtrain.T)).T\n",
    "            s = softmax(t)\n",
    "            error = s-temp\n",
    "            gradient = Xtrain.T@error \n",
    "            a = a - step_size*gradient\n",
    "    \n",
    "    return a\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "#------SIMPLE TESTING ON THE TRAINING DATA ITSELF --------------\n",
    "a = logisticRegressionMultiClassClassifier(X_train,y_train,iterations=500,verbose=False)\n",
    "plt.imshow(np.reshape(a[0:784],(28,28)))\n",
    "\n",
    "train = testLinearMCClassifier(a,X_train,y_train)\n",
    "val = testLinearMCClassifier(a,X_val,y_val)\n",
    "test = testLinearMCClassifier(a,X_test,y_test)\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis-classifications= 0 out of 61250 equivalent to 0.0 %\n",
      "Mis-classifications= 1 out of 8750 equivalent to 0.011428571428571429 %\n",
      "Mis-classifications= 1 out of 4354 equivalent to 0.022967386311437757 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdtklEQVR4nO3dfWyV9d3H8c/p0wGkPaWUPklhBR/YRLqMSdeoDEcDdIkB5Q+floAxGFkxQ+Y0LCrqlnTDxBkN0382mImoMxG4NfdYtNgSt8ICSgjZ1lDubsANLRNtT1voaen53X9we7bDo7+L037bw/uVXAnnnOvb69urV/mcq+c63xNyzjkBADDMMqwbAABcnQggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmMiybuBc8Xhcx44dU25urkKhkHU7AABPzjl1d3errKxMGRkXP88ZcQF07NgxlZeXW7cBALhCR44c0eTJky/6+IgLoNzcXEnSbfq+spRt3A0AwNcZDehj/Xfi//OLGbIA2rBhg1544QW1t7ersrJSr7zyiubMmXPZui//7JalbGWFCCAAGHX+f8Lo5V5GGZKLEN5++22tWbNG69at0yeffKLKykotXLhQJ06cGIrNAQBGoSEJoBdffFErVqzQgw8+qG984xt67bXXNG7cOP32t78dis0BAEahlAdQf3+/9u7dq5qamn9vJCNDNTU1am5uPm/9WCymaDSatAAA0l/KA+izzz7T4OCgiouLk+4vLi5We3v7eevX19crEokkFq6AA4Crg/kbUdeuXauurq7EcuTIEeuWAADDIOVXwRUWFiozM1MdHR1J93d0dKikpOS89cPhsMLhcKrbAACMcCk/A8rJydHs2bPV0NCQuC8ej6uhoUHV1dWp3hwAYJQakvcBrVmzRsuWLdO3v/1tzZkzRy+99JJ6e3v14IMPDsXmAACj0JAE0D333KN//etfeuaZZ9Te3q5vfvOb2r59+3kXJgAArl4h55yzbuI/RaNRRSIRzdNiJiEAwCh0xg2oUdvU1dWlvLy8i65nfhUcAODqRAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAExkWTcAjHqhkHUHo5dz1h3AEGdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDCMFCNfgGGfoZycQJvKyB3vXzQh4l0yOOEa75p4TqZ3TSjgrM/QYNy7JqPvjP92Tvf71/Sc8q5x3T3eNZIUP93nv60zA/4bukqHsnIGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwATDSDG8ggwWzfQfwpkRDnvXSAo0WLRv6gTvmp7J/sNS+3P9911QWaf9h2PmdPvXjPnCf4BpuCPbuyYj7j9cVZJCg4PeNS5AjVyAmjTAGRAAwAQBBAAwkfIAevbZZxUKhZKWGTNmpHozAIBRbkheA7rpppv04Ycf/nsjWbzUBABINiTJkJWVpZKSkqH40gCANDEkrwEdPHhQZWVlmjZtmh544AEdPnz4ouvGYjFFo9GkBQCQ/lIeQFVVVdq0aZO2b9+uV199VW1tbbr99tvV3d19wfXr6+sViUQSS3l5eapbAgCMQCHnnP/F+x46Ozs1depUvfjii3rooYfOezwWiykWiyVuR6NRlZeXa54WKyvkf70/Rrjheh/QuHHeNZKk4kLvEt4HdNbwvQ+o17sm48QX3jWSFI9e+InzJWtO9wXYUHq9D+iMG1Cjtqmrq0t5eXkXXW/Irw7Iz8/XDTfcoNbW1gs+Hg6HFQ76pkEAwKg15O8D6unp0aFDh1RaWjrUmwIAjCIpD6DHH39cTU1N+sc//qE///nPuuuuu5SZman77rsv1ZsCAIxiKf8T3NGjR3Xffffp5MmTmjRpkm677Tbt2rVLkyZNSvWmAACjWMoD6K233kr1lwT8BbhwQZKU43/hy0Cu/69R30T/CwpiEwJcLxTwEqPsngAXPAQoye4N8EeYABeyKOi1VkN7jdZVj1lwAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATAz5B9IBJlx82DY1mOM/HHPgGv/tDEwI8D0F3A0ZgwGHuXrK7PdvMHS637vGxfxrJMkN+H9i63Aee6MdZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMw0ZacoPBJhKHnPOuiQf4LRrI8+8va+Jp75ozfdneNZIU7/R/bpoZ899OdtR/SnUo2uNdE48FaE6SGxwMUOR/DF2tOAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggmGkSE/xYMNIgwySHMwJ+ddMGPCuqZj0hXfN0c/zvWskKdQf9q4JR89412R+3utdE+/xr3H9/kNPz24swDBSfGWcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBMFKMeC7uPyA0FGCoqCQpwLbOjPUfRjqppMu7pmriP7xrjnXO8q6RpKxu/5oxJ2L+RV9EvUtcn/923Bn/QakYepwBAQBMEEAAABPeAbRz507deeedKisrUygU0tatW5Med87pmWeeUWlpqcaOHauamhodPHgwVf0CANKEdwD19vaqsrJSGzZsuODj69ev18svv6zXXntNu3fv1jXXXKOFCxeqr6/vipsFAKQP74sQamtrVVtbe8HHnHN66aWX9NRTT2nx4sWSpNdff13FxcXaunWr7r333ivrFgCQNlL6GlBbW5va29tVU1OTuC8SiaiqqkrNzc0XrInFYopGo0kLACD9pTSA2tvbJUnFxcVJ9xcXFyceO1d9fb0ikUhiKS8vT2VLAIARyvwquLVr16qrqyuxHDlyxLolAMAwSGkAlZSUSJI6OjqS7u/o6Eg8dq5wOKy8vLykBQCQ/lIaQBUVFSopKVFDQ0Pivmg0qt27d6u6ujqVmwIAjHLeV8H19PSotbU1cbutrU379u1TQUGBpkyZotWrV+vnP/+5rr/+elVUVOjpp59WWVmZlixZksq+AQCjnHcA7dmzR3fccUfi9po1ayRJy5Yt06ZNm/TEE0+ot7dXDz/8sDo7O3Xbbbdp+/btGjNmTOq6BgCMet4BNG/ePLlLDHoMhUJ6/vnn9fzzz19RY8AViceHbVP9Ef+amtLWy690jpljj3rXvBWb7V0jSXkd/vsvu91/wGq823/qqTsz4F2Dkcn8KjgAwNWJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGDCexo2kNayMr1LTpf4T45emr/Hu6YzPs67Jv552LtGksYfjXnXuM+/8K6J9weYbH2JafwYXTgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIJhpMB/OJM3xrtm4vTPvWtm5Qx61/xXr/8w0rH/6z9cVZJyjvp/T4M9vf4bivvvB6QPzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYBgphpdz/jWhACU5Of5Fkk5d6z+MdF7Zfu+acRn+/R04Pdm7JvI/ce8aSXInv/CvGWSwKPxwBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEw0gxvEL+k0VDmZn+NRMneNdIUtc0/23dPO6Id82peL93zUft13vXjD/a510jSfFYzL8oyKBZXNU4AwIAmCCAAAAmvANo586duvPOO1VWVqZQKKStW7cmPb58+XKFQqGkZdGiRanqFwCQJrwDqLe3V5WVldqwYcNF11m0aJGOHz+eWN58880rahIAkH68L0Kora1VbW3tJdcJh8MqKSkJ3BQAIP0NyWtAjY2NKioq0o033qiVK1fq5MmTF103FospGo0mLQCA9JfyAFq0aJFef/11NTQ06Je//KWamppUW1urwYt8Xnx9fb0ikUhiKS8vT3VLAIARKOXvA7r33nsT/7755ps1a9YsTZ8+XY2NjZo/f/55669du1Zr1qxJ3I5Go4QQAFwFhvwy7GnTpqmwsFCtra0XfDwcDisvLy9pAQCkvyEPoKNHj+rkyZMqLS0d6k0BAEYR7z/B9fT0JJ3NtLW1ad++fSooKFBBQYGee+45LV26VCUlJTp06JCeeOIJXXfddVq4cGFKGwcAjG7eAbRnzx7dcccdidtfvn6zbNkyvfrqq9q/f79+97vfqbOzU2VlZVqwYIF+9rOfKRwOp65rAMCo5x1A8+bNk7vE0ME//vGPV9QQ0lzI/6++GeOv8a7pn1zgXSNJvdfGvWuuyfAfLPppv//1P8faCr1rZnQHe1uDizNYFEOPWXAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMp/0huXEVCIe+SjDEBPpajcIJ3SffUYB//ESqIedecHBzvXbOrZ7p3zdj/9f91DQ0MetdIksvw/9kGOR50icn6SH+cAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBMFIEGyIpKZST412TkZfrXdNfEvGuOVUU7LlVVo7/8M4Dvdd61+zq+Jp3TU7UuyT4zzYz07vGhYLs83iAmgAYejoicQYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABMNI002A4ZOhrOxAm8oYN867xk3M9645Xew/9HQgz7tEkhQf9H9Otu/kZO+af53wb7Ag5j9Q02X7DxWVpFCW/38NoYx+7xoXD/Ac2A3TAFMMOc6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAYaZoJZfoPnwyNCQfbViTXu6a/0H+AaV++//OkwRz/wZ2SdOa0/6/EsZMR75qMTv8BsKFB7xK5nGC/4qGcAANqYwGOPfl/Uy7AfggypPfsxoIdR/hqOAMCAJgggAAAJrwCqL6+Xrfccotyc3NVVFSkJUuWqKWlJWmdvr4+1dXVaeLEiRo/fryWLl2qjo6OlDYNABj9vAKoqalJdXV12rVrlz744AMNDAxowYIF6u3tTazz2GOP6b333tM777yjpqYmHTt2THfffXfKGwcAjG5er1Bu37496famTZtUVFSkvXv3au7cuerq6tJvfvMbbd68Wd/73vckSRs3btTXv/517dq1S9/5zndS1zkAYFS7oteAurq6JEkFBQWSpL1792pgYEA1NTWJdWbMmKEpU6aoubn5gl8jFospGo0mLQCA9Bc4gOLxuFavXq1bb71VM2fOlCS1t7crJydH+fn5SesWFxervb39gl+nvr5ekUgksZSXlwdtCQAwigQOoLq6Oh04cEBvvfXWFTWwdu1adXV1JZYjR45c0dcDAIwOgd6ltmrVKr3//vvauXOnJk+enLi/pKRE/f396uzsTDoL6ujoUElJyQW/VjgcVjgc7I2QAIDRy+sMyDmnVatWacuWLdqxY4cqKiqSHp89e7ays7PV0NCQuK+lpUWHDx9WdXV1ajoGAKQFrzOguro6bd68Wdu2bVNubm7idZ1IJKKxY8cqEonooYce0po1a1RQUKC8vDw9+uijqq6u5go4AEASrwB69dVXJUnz5s1Lun/jxo1avny5JOlXv/qVMjIytHTpUsViMS1cuFC//vWvU9IsACB9eAWQ+wqD+caMGaMNGzZow4YNgZvC/8sIMNwxy/9lvdCYMd41khQf7z9YtD/Pf8jl4Bj/QZKhwWBDJDO6/fdf/JT/zyn7VIDvKe5donh2sOuMMoMcRwEGfg7bqE+Gio5IzIIDAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgI9ImoGB6hDP/pwsoMMEE7x39CtSTFxwSYHJ09PJOts3sD7DtJGWcC1AUoyYgFqDkzjBOdA0y2DsLFmVJ9NeMMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAmGkaYbF2C44+BgoE2F+s5412RH/WvGZvkPS8065V0iSXL+s1zlggwj9d8NGvO5/88pMxpg6qkk19/vXzMYD7ChIDUMME0XnAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwTDSEcyd8Z9Y6eL+gxrdQIDJmJJCvf4TP8e053jXjM32H0aqjIDPrUIBJotmDs/zONfnP1jUdfcE2tZggG0pHmyoLa5enAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwTDSdBNgIKQLOETSDfT7F3UH2hSANMQZEADABAEEADDhFUD19fW65ZZblJubq6KiIi1ZskQtLS1J68ybN0+hUChpeeSRR1LaNABg9PMKoKamJtXV1WnXrl364IMPNDAwoAULFqi3tzdpvRUrVuj48eOJZf369SltGgAw+nldhLB9+/ak25s2bVJRUZH27t2ruXPnJu4fN26cSkpKUtMhACAtXdFrQF1dXZKkgoKCpPvfeOMNFRYWaubMmVq7dq1Onbr4RzfHYjFFo9GkBQCQ/gJfhh2Px7V69WrdeuutmjlzZuL++++/X1OnTlVZWZn279+vJ598Ui0tLXr33Xcv+HXq6+v13HPPBW0DADBKhZxzLkjhypUr9Yc//EEff/yxJk+efNH1duzYofnz56u1tVXTp08/7/FYLKZYLJa4HY1GVV5ernlarKxQdpDWAACGzrgBNWqburq6lJeXd9H1Ap0BrVq1Su+//7527tx5yfCRpKqqKkm6aACFw2GFw+EgbQAARjGvAHLO6dFHH9WWLVvU2NioioqKy9bs27dPklRaWhqoQQBAevIKoLq6Om3evFnbtm1Tbm6u2tvbJUmRSERjx47VoUOHtHnzZn3/+9/XxIkTtX//fj322GOaO3euZs2aNSTfAABgdPJ6DSgUCl3w/o0bN2r58uU6cuSIfvCDH+jAgQPq7e1VeXm57rrrLj311FOX/Dvgf4pGo4pEIrwGBACj1JC8BnS5rCovL1dTU5PPlwQAXKWYBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMJFl3cC5nHOSpDMakJxxMwAAb2c0IOnf/59fzIgLoO7ubknSx/pv404AAFeiu7tbkUjkoo+H3OUiapjF43EdO3ZMubm5CoVCSY9Fo1GVl5fryJEjysvLM+rQHvvhLPbDWeyHs9gPZ42E/eCcU3d3t8rKypSRcfFXekbcGVBGRoYmT558yXXy8vKu6gPsS+yHs9gPZ7EfzmI/nGW9Hy515vMlLkIAAJgggAAAJkZVAIXDYa1bt07hcNi6FVPsh7PYD2exH85iP5w1mvbDiLsIAQBwdRhVZ0AAgPRBAAEATBBAAAATBBAAwMSoCaANGzboa1/7msaMGaOqqir95S9/sW5p2D377LMKhUJJy4wZM6zbGnI7d+7UnXfeqbKyMoVCIW3dujXpceecnnnmGZWWlmrs2LGqqanRwYMHbZodQpfbD8uXLz/v+Fi0aJFNs0Okvr5et9xyi3Jzc1VUVKQlS5aopaUlaZ2+vj7V1dVp4sSJGj9+vJYuXaqOjg6jjofGV9kP8+bNO+94eOSRR4w6vrBREUBvv/221qxZo3Xr1umTTz5RZWWlFi5cqBMnTli3NuxuuukmHT9+PLF8/PHH1i0Nud7eXlVWVmrDhg0XfHz9+vV6+eWX9dprr2n37t265pprtHDhQvX19Q1zp0PrcvtBkhYtWpR0fLz55pvD2OHQa2pqUl1dnXbt2qUPPvhAAwMDWrBggXp7exPrPPbYY3rvvff0zjvvqKmpSceOHdPdd99t2HXqfZX9IEkrVqxIOh7Wr19v1PFFuFFgzpw5rq6uLnF7cHDQlZWVufr6esOuht+6detcZWWldRumJLktW7YkbsfjcVdSUuJeeOGFxH2dnZ0uHA67N99806DD4XHufnDOuWXLlrnFixeb9GPlxIkTTpJrampyzp392WdnZ7t33nknsc7f/vY3J8k1NzdbtTnkzt0Pzjn33e9+1/3oRz+ya+orGPFnQP39/dq7d69qamoS92VkZKimpkbNzc2Gndk4ePCgysrKNG3aND3wwAM6fPiwdUum2tra1N7ennR8RCIRVVVVXZXHR2Njo4qKinTjjTdq5cqVOnnypHVLQ6qrq0uSVFBQIEnau3evBgYGko6HGTNmaMqUKWl9PJy7H770xhtvqLCwUDNnztTatWt16tQpi/YuasQNIz3XZ599psHBQRUXFyfdX1xcrL///e9GXdmoqqrSpk2bdOONN+r48eN67rnndPvtt+vAgQPKzc21bs9Ee3u7JF3w+PjysavFokWLdPfdd6uiokKHDh3ST3/6U9XW1qq5uVmZmZnW7aVcPB7X6tWrdeutt2rmzJmSzh4POTk5ys/PT1o3nY+HC+0HSbr//vs1depUlZWVaf/+/XryySfV0tKid99917DbZCM+gPBvtbW1iX/PmjVLVVVVmjp1qn7/+9/roYceMuwMI8G9996b+PfNN9+sWbNmafr06WpsbNT8+fMNOxsadXV1OnDgwFXxOuilXGw/PPzww4l/33zzzSotLdX8+fN16NAhTZ8+fbjbvKAR/ye4wsJCZWZmnncVS0dHh0pKSoy6Ghny8/N1ww03qLW11boVM18eAxwf55s2bZoKCwvT8vhYtWqV3n//fX300UdJH99SUlKi/v5+dXZ2Jq2frsfDxfbDhVRVVUnSiDoeRnwA5eTkaPbs2WpoaEjcF4/H1dDQoOrqasPO7PX09OjQoUMqLS21bsVMRUWFSkpKko6PaDSq3bt3X/XHx9GjR3Xy5Mm0Oj6cc1q1apW2bNmiHTt2qKKiIunx2bNnKzs7O+l4aGlp0eHDh9PqeLjcfriQffv2SdLIOh6sr4L4Kt566y0XDofdpk2b3F//+lf38MMPu/z8fNfe3m7d2rD68Y9/7BobG11bW5v705/+5GpqalxhYaE7ceKEdWtDqru723366afu008/dZLciy++6D799FP3z3/+0znn3C9+8QuXn5/vtm3b5vbv3+8WL17sKioq3OnTp407T61L7Yfu7m73+OOPu+bmZtfW1uY+/PBD961vfctdf/31rq+vz7r1lFm5cqWLRCKusbHRHT9+PLGcOnUqsc4jjzzipkyZ4nbs2OH27NnjqqurXXV1tWHXqXe5/dDa2uqef/55t2fPHtfW1ua2bdvmpk2b5ubOnWvcebJREUDOOffKK6+4KVOmuJycHDdnzhy3a9cu65aG3T333ONKS0tdTk6Ou/baa90999zjWltbrdsach999JGTdN6ybNky59zZS7GffvppV1xc7MLhsJs/f75raWmxbXoIXGo/nDp1yi1YsMBNmjTJZWdnu6lTp7oVK1ak3ZO0C33/ktzGjRsT65w+fdr98Ic/dBMmTHDjxo1zd911lzt+/Lhd00Pgcvvh8OHDbu7cua6goMCFw2F33XXXuZ/85Ceuq6vLtvFz8HEMAAATI/41IABAeiKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGDi/wBFw2P4czH9/AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def logisticRegressionMultiClassClassifierWithRegularization(Xtrain,ytrain,iterations=100,step_size=1e-4,lam=0,verbose=False):\n",
    "    Xtrain = Xtrain.T\n",
    "    test = np.zeros((Xtrain.shape[0],1))\n",
    "    Xtrain = np.append(Xtrain,test,axis=1)  \n",
    "\n",
    "    a = 0.01*np.random.randn(Nfeatures+1)\n",
    "    t = np.squeeze(a.T@Xtrain.T)\n",
    "    s = softmax(t)\n",
    "    error = s-ytrain\n",
    "    for i in range(iterations):\n",
    "        replace_y = ytrain\n",
    "        temp=[1 if replace_y[x] ==1 else 0 for x in range(replace_y.shape[0])]\n",
    "        for j in range(Nclasses):\n",
    "            t = np.squeeze(np.matmul(np.transpose(a),Xtrain.T)).T\n",
    "            s = softmax(t)\n",
    "            error = s-temp\n",
    "            gradient = Xtrain.T@error + (np.dot((np.dot(lam,a)),2))\n",
    "            a = a - step_size*gradient\n",
    "    return a\n",
    "\n",
    "a = logisticRegressionMultiClassClassifierWithRegularization(X_train,y_train,iterations=500,verbose=False,lam=1)\n",
    "plt.imshow(np.reshape(a[0:784],(28,28)))\n",
    "\n",
    "train = testLinearMCClassifier(a,X_train,y_train)\n",
    "val = testLinearMCClassifier(a,X_val,y_val)\n",
    "test = testLinearMCClassifier(a,X_test,y_test)\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 61251 is different from 785)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\Adnane Ezouhri\\Desktop\\School\\Machine_Learning\\Project\\Component2.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     lamopt \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(temp)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lamopt\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m a1 \u001b[39m=\u001b[39m Optimize_MC_Hyperparameters(X_train,y_train)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# a = logisticRegressionMultiClassClassifierWithRegularization(X_train,y_train,iterations=500,verbose=False,lam = a1)\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(np\u001b[39m.\u001b[39mreshape(a[\u001b[39m0\u001b[39m:\u001b[39m784\u001b[39m],(\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m)))\n",
      "\n",
      "\u001b[1;32mc:\\Users\\Adnane Ezouhri\\Desktop\\School\\Machine_Learning\\Project\\Component2.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#looping to find the best lamda to call the logisticRegressionWithRegularization method\u001b[39;00m\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m lam:\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     a \u001b[39m=\u001b[39mlogisticRegressionMultiClassClassifierWithRegularization(Xtrain,ytrain,\u001b[39m100\u001b[39;49m,\u001b[39m1e-4\u001b[39;49m,i,\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     b \u001b[39m=\u001b[39m testLinearMCClassifier(a,Xtrain,ytrain)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     temp\u001b[39m.\u001b[39mappend(b)\n",
      "\n",
      "\u001b[1;32mc:\\Users\\Adnane Ezouhri\\Desktop\\School\\Machine_Learning\\Project\\Component2.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Xtrain \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(Xtrain,test,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(Nfeatures\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m t \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(a\u001b[39m.\u001b[39;49mT\u001b[39m@Xtrain\u001b[39;49m\u001b[39m.\u001b[39;49mT)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m s \u001b[39m=\u001b[39m softmax(t)\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Adnane%20Ezouhri/Desktop/School/Machine_Learning/Project/Component2.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m error \u001b[39m=\u001b[39m s\u001b[39m-\u001b[39mytrain\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 61251 is different from 785)"
     ]
    }
   ],
   "source": [
    "def Optimize_MC_Hyperparameters(Xtrain,ytrain):\n",
    "    # YOUR CODE HERE\n",
    "    #0-100 with step size 100\n",
    "    Xtrain = Xtrain.T \n",
    "    temp = []\n",
    "    lam= np.linspace(0,100,num = 100)\n",
    "    #looping to find the best lamda to call the logisticRegressionWithRegularization method\n",
    "    for i in lam:\n",
    "        a =logisticRegressionMultiClassClassifierWithRegularization(Xtrain,ytrain,100,1e-4,i,False)\n",
    "        b = testLinearMCClassifier(a,Xtrain,ytrain)\n",
    "        temp.append(b)\n",
    "        \n",
    "    lamopt = min(temp)\n",
    "\n",
    "    return lamopt\n",
    "\n",
    "\n",
    "a1 = Optimize_MC_Hyperparameters(X_train,y_train)\n",
    "# a = logisticRegressionMultiClassClassifierWithRegularization(X_train,y_train,iterations=500,verbose=False,lam = a1)\n",
    "plt.imshow(np.reshape(a[0:784],(28,28)))\n",
    "train = testLinearMCClassifier(a,X_train,y_train)\n",
    "val = testLinearMCClassifier(a,X_val,y_val)\n",
    "test = testLinearMCClassifier(a,X_test,y_test)\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is for a1\n",
      "Mis-classifications= 44955 out of 61250 equivalent to 73.39591836734694 %\n",
      "Mis-classifications= 6355 out of 8750 equivalent to 72.62857142857143 %\n",
      "Mis-classifications= 617 out of 4354 equivalent to 14.170877354157096 %\n",
      "-------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#######################################\u001b[39;00m\n",
      "\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# This is a2 and you will notice that the percentage is better than a1\u001b[39;00m\n",
      "\u001b[0;32m---> 14\u001b[0m a2 \u001b[38;5;241m=\u001b[39m \u001b[43mlogisticRegressionMultiClassClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     15\u001b[0m train1 \u001b[38;5;241m=\u001b[39m testLinearMCClassifier(a2,X_train,y_train)\n",
      "\u001b[1;32m     16\u001b[0m val1 \u001b[38;5;241m=\u001b[39m testLinearMCClassifier(a2,X_val,y_val)\n",
      "\n",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36mlogisticRegressionMultiClassClassifier\u001b[0;34m(Xtrain, ytrain, iterations, step_size, verbose)\u001b[0m\n",
      "\u001b[1;32m     18\u001b[0m         gradient \u001b[38;5;241m=\u001b[39m Xtrain\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@error\u001b[39m \n",
      "\u001b[1;32m     19\u001b[0m         a \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m-\u001b[39m step_size\u001b[38;5;241m*\u001b[39mgradient\n",
      "\u001b[0;32m---> 20\u001b[0m     \u001b[43mlist_a\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m a\n",
      "\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m list_a\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "#call all the method and set them eqiual to a1-4 and show that we see lower class\n",
    "# This is a1 and you can tell that this one will be the highest precentage so the worst one to pick\n",
    "a1 = gaussianMultiChannelClassifier(X_train,y_train)\n",
    "train = testLinearMCClassifier(a1,X_train,y_train)\n",
    "val = testLinearMCClassifier(a1,X_val,y_val)\n",
    "test = testLinearMCClassifier(a1,X_test,y_test)\n",
    "print(\"This is for a1\")\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\") \n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "#######################################\n",
    "# This is a2 and you will notice that the percentage is better than a1\n",
    "a2 = logisticRegressionMultiClassClassifier(X_train,y_train)\n",
    "train1 = testLinearMCClassifier(a2,X_train,y_train)\n",
    "val1 = testLinearMCClassifier(a2,X_val,y_val)\n",
    "test1 = testLinearMCClassifier(a2,X_test,y_test)\n",
    "print(\"This is for a2\")\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\") \n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "#######################################\n",
    "# This is a3 and you will notice that the percentage is better than a1 and a2\n",
    "a3 = logisticRegressionMultiClassClassifierWithRegularization(X_train,y_train,iterations=500,verbose=False)\n",
    "train2 = testLinearMCClassifier(a3,X_train,y_train)\n",
    "val2 = testLinearMCClassifier(a3,X_val,y_val)\n",
    "test2 = testLinearMCClassifier(a3,X_test,y_test)\n",
    "print(\"This is for a3\")\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\") \n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "#######################################\n",
    "# This is a4 and you will notice that the percentage is better then everyone\n",
    "a4 = Optimize_MC_Hyperparameters(X_train,y_train,iterations=500,verbose=False,lam=1)\n",
    "train3 = testLinearMCClassifier(a4,X_train,y_train)\n",
    "val3 = testLinearMCClassifier(a4,X_val,y_val)\n",
    "test3 = testLinearMCClassifier(a4,X_test,y_test)\n",
    "print(\"This is for a4\")\n",
    "print(\"Mis-classifications=\", train, \"out of\",X_train.T.shape[0], \"equivalent to\",(train/X_train.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", val, \"out of\",X_val.T.shape[0], \"equivalent to\",(val/X_val.T.shape[0])*100 ,\"%\")\n",
    "print(\"Mis-classifications=\", test, \"out of\",X_test.T.shape[0], \"equivalent to\",(test/X_test.T.shape[0])*100 ,\"%\") \n",
    "print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "####################\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
